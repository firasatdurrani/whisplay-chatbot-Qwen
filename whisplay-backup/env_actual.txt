## Core servers
# options: openai, gemini, tencent, volcengine, whisper, vosk
ASR_SERVER=WHISPER 

# options: openai, gemini, grok, volcengine, ollama
LLM_SERVER=OLLAMA

# options: openai, gemini, tencent, volcengine, piper
TTS_SERVER=PIPER

# options: openai, gemini, volcengine
IMAGE_GENERATION_SERVER=openai

## Grok
# if you are using grok as LLM server, please set the following environment variables
GROK_API_KEY=your_grok_api_key
# the default model is grok-4-latest
# GROK_LLM_MODEL=grok-4-latest

## Ollama
# local Ollama endpoint and model used by Whisplay
OLLAMA_ENDPOINT=http://localhost:11434
# the default model is qwen3:1.7b, change if you like
OLLAMA_MODEL=qwen3:1.7b
# start/stop ollama automatically from run_chatbot.sh
SERVE_OLLAMA=true
# if you want to enable tools for ollama, uncomment the following line (make sure the model supports tools)
# OLLAMA_ENABLE_TOOLS=true
# if you are using ollama as VISION_SERVER, specify the vision model for ollama image understanding tasks, default is qwen3-vl:2b
# OLLAMA_VISION_MODEL=qwen3-vl:2b

## Proxy Settings
# proxy settings for all cloud api request, uncomment the following lines if you need to use a proxy to access the internet
# usually you only need to set HTTPS_PROXY
# HTTPS_PROXY=https://your_https_proxy
# HTTP_PROXY=http://your_http_proxy
# ALL_PROXY=socks5://your_socks_proxy

## Custom System Prompt
# you can set a custom system prompt for LLM, please uncomment the following line and set your own prompt
# SYSTEM_PROMPT="You are a helpful assistant. Answer concisely in English."

## Piper TTS
# Piper is an open-source TTS engine that can run locally on your device
# PIPER_EXE must point to the actual binary that works from your shell
PIPER_EXE=/home/pi/.local/bin/piper

# IMPORTANT: this must match where the installer (and you) put the voices
# You are downloading:
#   /home/pi/piper/voices/en_US-amy-medium.onnx
#   /home/pi/piper/voices/en_US-amy-medium.onnx.json
PIPER_VOICES_DIR=/home/pi/piper/voices
PIPER_VOICE=en_US-amy-medium

## Vosk ASR
# if you are using vosk as ASR server, please set the following environment variables
# Vosk is an open-source ASR engine that can run locally on your device
# You can download Vosk binaries and models from: https://alphacephei.com/vosk/models
# unzip the model to a folder and set the path below
VOSK_MODEL_PATH=/path/to/vosk/model

## Whisper ASR
# Whisper is an open-source ASR engine that can run locally on your device
# https://github.com/openai/whisper
# the default model size is tiny, you can also choose other model sizes: tiny, base, small, medium, large.
WHISPER_MODEL_SIZE=tiny
# If you want to force English output and avoid Arabic, uncomment the next line:
# WHISPER_LANGUAGE=English

## Chat history and data
# specify the chat history reset time in seconds, default is 5 minutes (300 seconds)
# CHAT_HISTORY_RESET_TIME=300

# if you want to clean the data folder on each start, set the following environment variable to true
# CLEAN_DATA_FOLDER_ON_START=true

# enable or disable thinking of LLM
# if you are using ollama as LLM server, please confirm that the model supports thinking before enabling this option
# otherwise ollama will return a 400 error
ENABLE_THINKING=false

## Pi Camera
# if you want to enable the Pi Camera for image capture (double click the button in idle status to enter) uncomment the following line:
# ENABLE_CAMERA=true

## Tencent Cloud ASR and TTS
# if you are using tencent cloud as ASR or TTS server, please set the following environment variables
TENCENT_SECRET_ID=YourSecretId
TENCENT_SECRET_KEY=YourSecretKey
# endpoint is optional, default is asr.tencentcloudapi.com for ASR and tts.tencentcloudapi.com for TTS
# TENCENT_ASR_ENDPOINT=asr.tencentcloudapi.com
# TENCENT_TTS_ENDPOINT=tts.tencentcloudapi.com

## ByteDance VolcEngine ASR and TTS
# if you are using volcengine as ASR or TTS server, please set the following environment variables
# VOLCENGINE_APP_ID=volcengine_app_id
VOLCENGINE_ACCESS_TOKEN=volcengine_access_token
# VOLCENGINE_VOICE_TYPE=zh_female_wanwanxiaohe_moon_bigtts

## ByteDance Doubao LLM
# if you are using volcengine as LLM server, please set the following environment variables
VOLCENGINE_DOUBAO_ACCESS_TOKEN=volcengine_doubao_access_token
# VOLCENGINE_DOUBAO_LLM_MODEL=doubao-1-5-lite-32k-250115
# VOLCENGINE_DOUBAO_IMAGE_MODEL=doubao-seedream-3-0-t2i-250415
# VOLCENGINE_DOUBAO_VISION_MODEL=doubao-seed-1-6-flash-250828

## Google Gemini
# if you are using google gemini as ASR / LLM / TTS / IMAGE_GENERATION server, please set the following environment variables
GEMINI_API_KEY=your_api_key
# GEMINI_MODEL=
